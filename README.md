# Git Practice
# Kylie Lin - Reflections on System Design & Complexity

I recently read [The $1,500 Bug and the Art of System Design](https://medium.com/@dylannoorland/the-1500-dollar-bug-a3386dbf1260) by Dylan Noorland. The article describes a real incident where a solo developer accidentally charged a customer **$1,500** instead of the correct subscription fee because of a subtle **currency conversion bug**. At first, it seems like nothing more than a small technical error. However, what made the article so interesting to me is that the story is less about one mistake and more about the **challenges of complexity in software systems**, the hidden assumptions developers make, and the **cognitive burden** that grows as projects get larger.  

What stood out to me most is the idea that building software is not just about making something work on the surface—it is about **truly understanding the systems you own**. Noorland points out that it is easy to plug in code or use an API that “works” without really knowing how it behaves in all possible situations. When that happens, you end up carrying **invisible risks**. For him, the risk was tied to dealing with currencies, decimals, and payment APIs. These seemed like small details until they suddenly caused a very expensive problem. This made me think about how often developers (myself included) might assume that tools or integrations will behave as expected, only to discover later that we do not fully understand their edge cases.  

Another part of the article I found thought-provoking was the discussion of **cognitive load**. Every feature that gets added to a system isn’t just more code—it is more mental weight for the developer. Even when you are not actively working on that feature, it is still in the background as something you are responsible for. Noorland admitted that some of the features he had built, like his own custom currency abstractions, were not worth the extra responsibility. Instead of continuing to support them, he made the decision to simplify by removing unnecessary parts and relying more on **Stripe’s standard checkout system**. This reminded me that sometimes the smartest decision is not to add more, but to take things away.  

I also thought the author’s point about **“boring” solutions** was very important. Developers often feel pressure to create something new, clever, or custom. But this story shows the real value of choosing reliable, battle-tested tools. Stripe’s built-in system may not be as flashy as writing your own payment flow, but it is much safer and reduces the chance of making costly mistakes. In fact, using a “boring” but proven solution frees up mental energy so that developers can focus on the parts of a project that really matter.  

The larger lesson I took away from the article is that **software engineering is as much about trade-offs and sustainability as it is about building new features**. Every abstraction or system decision should be measured not only by what it can do, but also by how much complexity it adds, whether the developer fully understands it, and whether it is worth the long-term cost. Bugs like the one in this story don’t just cost money—they also damage trust, consume time, and drain a developer’s confidence. Reading this article reminded me that one of the most important skills in engineering is knowing when to **simplify, delegate to trusted tools, and keep systems lean and maintainable**.  

# Jasir
I'm not necessarily a software engineer, but a lot of this article reminds my of my past (and current) struggles in training models and deploying them. I particularly recall creating a novel method to evaluate my model outputs, thinking that it would provide a more "truthful" evaluation than current methods. However, when I considered the further experimentation to find all the edge cases that could be exploited to get a high score on the metric for erroneous outputs as well as the difficulty in explaining the metric to the stakeholders on the deployment, I too had to go with the "boring" option. It certainly stung to say no to my own creation for a little bit, but that pain was largely forgotten as my contributions to other portions of the model deployment ended up being more impactful. In the end, I can still experiment with the metric on my own and deploy it later down the line, but a stable product is of paramount importance when there are stakeholders other than myself involved.
